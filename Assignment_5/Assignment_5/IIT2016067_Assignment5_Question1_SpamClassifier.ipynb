{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (1.16.2)\n",
      "Requirement already satisfied: matplotlib in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (3.0.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (from matplotlib) (1.16.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/maanasvohra/Desktop/SCO_V2/env_setup/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n"
     ]
    }
   ],
   "source": [
    "# library installation\n",
    "\n",
    "!pip3 install numpy\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function : extract data\n",
    "\n",
    "def extract_data() :\n",
    "    data = [];\n",
    "    \n",
    "    with open('spam.csv', encoding=\"ISO-8859-1\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "#                 print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                data.append(row)\n",
    "                line_count += 1\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function : data preprocessing\n",
    "# returns training data, testing data, output, and word frequency\n",
    "def pre_process_data(data) :\n",
    "\n",
    "    # remove the stop words from the set, as they do not contribute to whether email is spam or not \n",
    "    stop_words = [\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "                  \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \n",
    "                  \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\",\n",
    "                  \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\",\n",
    "                  \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\",\n",
    "                  \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\",\n",
    "                  \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n",
    "                  \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\",\n",
    "                  \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\",\n",
    "                  \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
    "                  \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\",\n",
    "                  \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n",
    "                  \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\",\n",
    "                  \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "    # [SOURCE] : https://gist.github.com/sebleier/554280\n",
    "\n",
    "    # (1) Create vector of spam, ham\n",
    "    Y = []\n",
    "    for i in range(len(data)) :\n",
    "        Y.append(data[i][0])\n",
    "\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # (2) Consider only those elements without special characters => a-z, A-Z, 0-9\n",
    "\n",
    "    word_freq = {}\n",
    "    altered_data = []\n",
    "\n",
    "    for i in range(len(data)) :\n",
    "        dataRow = data[i][1 : ]\n",
    "        dataRow = \" \".join(dataRow)\n",
    "        newDataRow = \"\"\n",
    "        # consider only letters that are alphanumeric\n",
    "        for j in range(len(dataRow)) :\n",
    "            if(dataRow[j].isalnum() == False) :\n",
    "                tmp = \" \" \n",
    "            else :\n",
    "                tmp = dataRow[j]\n",
    "            newDataRow = newDataRow + tmp\n",
    "        newDataRow = newDataRow.split(\" \")\n",
    "\n",
    "        # convert every word to lower case\n",
    "        for j in range(len(newDataRow)) :\n",
    "            newDataRow[j] = newDataRow[j].lower()\n",
    "            \n",
    "        new_altered_data_row = []\n",
    "        word_set = set()\n",
    "\n",
    "        # only consider those words that aren't in the stop words dictionary\n",
    "        for j in range(len(newDataRow)) :\n",
    "            word = newDataRow[j]\n",
    "            if(word in stop_words) :\n",
    "                continue\n",
    "            else :\n",
    "                word_set.add(word) # we don't want duplicate entries\n",
    "        for word in word_set :\n",
    "            new_altered_data_row.append(word)\n",
    "        altered_data.append(new_altered_data_row)\n",
    "    \n",
    "    altered_data = np.array(altered_data)\n",
    "        \n",
    "    # (3) divide into training and testing data => 70% training and 30% test\n",
    "        \n",
    "    train_size = int((altered_data.shape[0] * 7) / 10) # 70% train data\n",
    "    X_train_indices = random.sample(range(0, altered_data.shape[0]), train_size)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = [], [], [], []\n",
    "    for i in range(altered_data.shape[0]) :\n",
    "        if(i in X_train_indices) :\n",
    "            X_train.append(altered_data[i])\n",
    "            Y_train.append(Y[i])\n",
    "        else :\n",
    "            X_test.append(altered_data[i])\n",
    "            Y_test.append(Y[i])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_test = np.array(Y_test)\n",
    "    \n",
    "    # (4) Make a dictionary for all the word count\n",
    "    for i in range(len(X_train)) :\n",
    "        for j in range(len(X_train[i])) :\n",
    "            word = X_train[i][j]\n",
    "            if(word not in stop_words) :\n",
    "                if(word not in word_freq) :\n",
    "                    word_freq[word] = 1\n",
    "                else:\n",
    "                    word_freq[word] = word_freq[word] + 1\n",
    "                    \n",
    "    return (X_train, X_test, Y_train, Y_test, word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and testing data\n",
    "def X_transform(data, word_freq) :\n",
    "    new_data = []\n",
    "    for i in range(data.shape[0]):\n",
    "        tmp = []\n",
    "        for val in word_freq :\n",
    "            if val in data[i] : \n",
    "                tmp.append(float(1));\n",
    "            else :\n",
    "                tmp.append(float(0));\n",
    "        tmp = np.array(tmp)\n",
    "        new_data.append(tmp)\n",
    "\n",
    "    new_data = np.array(new_data)\n",
    "    return new_data\n",
    "\n",
    "def Y_transform(data) :\n",
    "    new_data = []\n",
    "    for i in range(data.shape[0]) :\n",
    "        if(data[i] == \"spam\") :\n",
    "            new_data.append(float(1))\n",
    "        else :\n",
    "            new_data.append(float(0))\n",
    "    new_data = np.array(new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all necessary data\n",
    "data = extract_data()\n",
    "(X_train, X_test, Y_train, Y_test, word_freq) = pre_process_data(data)\n",
    "\n",
    "# transform data\n",
    "X_train = X_transform(X_train, word_freq)\n",
    "X_test = X_transform(X_test, word_freq)\n",
    "Y_train = Y_transform(Y_train)\n",
    "Y_test = Y_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required function for naive baysian\n",
    "# we have used the bernoulli model \n",
    "\n",
    "# prediction for y\n",
    "def y_prediction(Y_train) :\n",
    "    den = float(Y_train.shape[0])\n",
    "    num = 0\n",
    "    for i in range(Y_train.shape[0]) :\n",
    "        num = num + Y_train[i]\n",
    "    num = float(num)\n",
    "    return float(num / den)\n",
    "\n",
    "# probability for some y value\n",
    "def y_probability(Y_train, y_val) :\n",
    "    phi = y_prediction(Y_train)\n",
    "    val1 = phi ** y_val\n",
    "    val2 = (float(1) - phi) ** (1 - y_val)\n",
    "    \n",
    "    return val1 * val2\n",
    "\n",
    "# prediction for x_j(jth word of dictionary) when y = 1\n",
    "def x_prediction_1(X_train, Y_train, word_index) :\n",
    "    den = 0\n",
    "    for i in range(Y_train.shape[0]) :\n",
    "        den = den + Y_train[i]\n",
    "    den = float(den)\n",
    "    \n",
    "    num = 0\n",
    "    for i in range(X_train.shape[0]) :\n",
    "        if(Y_train[i] == 1 and X_train[i][word_index] == 1) :\n",
    "            num = num + 1\n",
    "    num = float(num)\n",
    "    \n",
    "    return float((num + float(1))/ (den + float(2)))\n",
    "\n",
    "# prediction for x when y = 0\n",
    "def x_prediction_0(X_train, Y_train, word_index) :\n",
    "    den = 0\n",
    "    for i in range(Y_train.shape[0]) :\n",
    "        den = den + (float(1) - Y_train[i])\n",
    "    den = float(den)\n",
    "    \n",
    "    num = 0\n",
    "    for i in range(X_train.shape[0]) :\n",
    "        if(Y_train[i] == 0 and X_train[i][word_index] == 1) :\n",
    "            num = num + 1\n",
    "    num = float(num)\n",
    "    \n",
    "    return float((num + float(1))/ (den + float(2)))\n",
    "\n",
    "# probability for some value of y,  for some jth word of dictionary\n",
    "def x_probability(X_train, Y_train, phi, x_val) :\n",
    "    val1 = phi ** x_val\n",
    "    val2 = (1 - phi) ** (1 - x_val)\n",
    "    \n",
    "    return val1  * val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store values because it's taking lot of time\n",
    "y_prob_1 = y_probability(Y_train, 1)\n",
    "y_prob_0 = y_probability(Y_train, 0)\n",
    "\n",
    "x_phi_vals_1 = np.zeros(X_train.shape[1])\n",
    "x_phi_vals_0 = np.zeros(X_train.shape[1])\n",
    "\n",
    "for i in range(X_train.shape[1]) :\n",
    "    x_phi_vals_1[i] = x_prediction_1(X_train, Y_train, i)\n",
    "    x_phi_vals_0[i] = x_prediction_0(X_train, Y_train, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing prediction for :  500\n",
      "Doing prediction for :  1000\n",
      "Doing prediction for :  1500\n",
      "Doing prediction for :  2000\n",
      "Doing prediction for :  2500\n",
      "Doing prediction for :  3000\n",
      "Doing prediction for :  3500\n",
      "Percentage accuracy on training data:  98.64102564102564\n"
     ]
    }
   ],
   "source": [
    "# check accuracy for training data\n",
    "\n",
    "total_correct = 0\n",
    "for i in range(X_train.shape[0]) :\n",
    "    if((i + 1) % 500 == 0) :\n",
    "        print(\"Doing prediction for : \", i + 1)\n",
    "    \n",
    "    den = float(0)\n",
    "    den1 = y_prob_1\n",
    "    for j in range(X_train.shape[1]) :\n",
    "        den1 = den1 * x_probability(X_train, Y_train, x_phi_vals_1[j], X_train[i][j])\n",
    "    den = den + den1\n",
    "    den1 = y_prob_0\n",
    "    for j in range(X_train.shape[1]) :\n",
    "        den1 = den1 * x_probability(X_train, Y_train, x_phi_vals_0[j], X_train[i][j])\n",
    "    den = den + den1\n",
    "\n",
    "    # for spam prediction\n",
    "    num = float(0)\n",
    "    num1 = y_prob_1\n",
    "    for j in range(X_train.shape[1]) :\n",
    "        num1 = num1 * x_probability(X_train, Y_train, x_phi_vals_1[j], X_train[i][j])\n",
    "    num = num + num1\n",
    "    \n",
    "    spam_prediction = num / den\n",
    "    \n",
    "    # for spam prediction\n",
    "    num = float(0)\n",
    "    num1 = y_prob_0\n",
    "    for j in range(X_train.shape[1]) :\n",
    "        num1 = num1 * x_probability(X_train, Y_train, x_phi_vals_0[j], X_train[i][j])\n",
    "    num = num + num1\n",
    "    \n",
    "    ham_prediction = num / den\n",
    "    \n",
    "    if(spam_prediction >= ham_prediction and Y_train[i] == 1) :\n",
    "        total_correct = total_correct + 1\n",
    "    elif(spam_prediction < ham_prediction and Y_train[i] == 0) :\n",
    "        total_correct = total_correct + 1\n",
    "                \n",
    "percentage_accuracy = (float(total_correct) / float(X_train.shape[0])) * 100\n",
    "print('Percentage accuracy on training data: ', percentage_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3847, 3900)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct, X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing prediction for :  300\n",
      "Doing prediction for :  600\n",
      "Doing prediction for :  900\n",
      "Doing prediction for :  1200\n",
      "Doing prediction for :  1500\n",
      "Percentage accuracy on testing data:  97.72727272727273\n"
     ]
    }
   ],
   "source": [
    "# check accuracy for testing data\n",
    "\n",
    "total_correct = 0\n",
    "for i in range(X_test.shape[0]) :\n",
    "    if((i + 1) % 300 == 0) :\n",
    "        print(\"Doing prediction for : \", i + 1)\n",
    "    \n",
    "    den = float(0)\n",
    "    den1 = y_prob_1\n",
    "    for j in range(X_test.shape[1]) :\n",
    "        den1 = den1 * x_probability(X_train, Y_train, x_phi_vals_1[j], X_test[i][j])\n",
    "    den = den + den1\n",
    "    den1 = y_prob_0\n",
    "    for j in range(X_test.shape[1]) :\n",
    "        den1 = den1 * x_probability(X_train, Y_train, x_phi_vals_0[j], X_test[i][j])\n",
    "    den = den + den1\n",
    "\n",
    "    # for spam prediction\n",
    "    num = float(0)\n",
    "    num1 = y_prob_1\n",
    "    for j in range(X_test.shape[1]) :\n",
    "        num1 = num1 * x_probability(X_train, Y_train, x_phi_vals_1[j], X_test[i][j])\n",
    "    num = num + num1\n",
    "    \n",
    "    spam_prediction = num / den\n",
    "    \n",
    "    # for spam prediction\n",
    "    num = float(0)\n",
    "    num1 = y_prob_0\n",
    "    for j in range(X_test.shape[1]) :\n",
    "        num1 = num1 * x_probability(X_train, Y_train, x_phi_vals_0[j], X_test[i][j])\n",
    "    num = num + num1\n",
    "    \n",
    "    ham_prediction = num / den\n",
    "    \n",
    "    if(spam_prediction >= ham_prediction and Y_test[i] == 1) :\n",
    "        total_correct = total_correct + 1\n",
    "    elif(spam_prediction < ham_prediction and Y_test[i] == 0) :\n",
    "        total_correct = total_correct + 1\n",
    "                \n",
    "percentage_accuracy = (float(total_correct) / float(X_test.shape[0])) * 100\n",
    "print('Percentage accuracy on testing data: ', percentage_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1634, 1672)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct, X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
